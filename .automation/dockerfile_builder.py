# !/usr/bin/env python3
"""
Dockerfile generation functions for MegaLinter build system
"""
import json
import logging
import os
import re
import shutil
from shutil import copyfile

import megalinter
import requests
import yaml

from build_constants import *
from utils_build import replace_in_file


def generate_all_flavors():
    """Generate one Dockerfile by MegaLinter flavor"""
    flavors = megalinter.flavor_factory.list_megalinter_flavors()

    for flavor, flavor_info in flavors.items():
        generate_flavor(flavor, flavor_info)
    update_mkdocs_and_workflow_yml_with_flavors()
    if UPDATE_STATS is True:
        try:
            update_docker_pulls_counter()
        except requests.exceptions.ConnectionError as e:
            logging.warning(
                "Connection error - Unable to update docker pull counters: " + str(e)
            )
        except Exception as e:
            logging.warning("Unable to update docker pull counters: " + str(e))


def generate_flavor(flavor, flavor_info):
    """Automatically generate Dockerfile, action.yml and upgrade all_flavors.json"""
    descriptor_and_linters = []
    flavor_descriptors = []
    flavor_linters = []
    # Get install instructions at descriptor level
    descriptor_files = megalinter.linter_factory.list_descriptor_files()
    for descriptor_file in descriptor_files:
        with open(descriptor_file, "r", encoding="utf-8") as f:
            descriptor = yaml.safe_load(f)
            if (
                match_flavor(descriptor, flavor, flavor_info) is True
                and "install" in descriptor
            ):
                descriptor_and_linters += [descriptor]
                flavor_descriptors += [descriptor["descriptor_id"]]
    # Get install instructions at linter level
    linters = megalinter.linter_factory.list_all_linters(({"request_id": "build"}))
    requires_docker = False
    for linter in linters:
        if match_flavor(vars(linter), flavor, flavor_info) is True:
            descriptor_and_linters += [vars(linter)]
            flavor_linters += [linter.name]
            if linter.cli_docker_image is not None:
                requires_docker = True
    # Initialize Dockerfile
    if flavor == "all":
        dockerfile = f"{REPO_HOME}/Dockerfile"
        if RELEASE is True:
            image_release = RELEASE_TAG
            action_yml = f"""# Automatically {'@'}generated by build.py
name: "MegaLinter"
author: "Nicolas Vuillamy"
description: "Combine all available linters to automatically validate your sources without configuration !"
outputs:
  has_updated_sources:
    description: "0 if no source file has been updated, 1 if source files has been updated"
runs:
  using: "docker"
  image: "docker://{ML_DOCKER_IMAGE}:{image_release}"
  args:
    - "-v"
    - "/var/run/docker.sock:/var/run/docker.sock:rw"
branding:
  icon: "check"
  color: "green"
"""
            main_action_yml = "action.yml"
            with open(main_action_yml, "w", encoding="utf-8") as file:
                file.write(action_yml)
                logging.info(f"Updated {main_action_yml}")
    else:
        # Flavor json
        flavor_file = f"{FLAVORS_DIR}/{flavor}/flavor.json"
        if os.path.isfile(flavor_file):
            with open(flavor_file, "r", encoding="utf-8") as json_file:
                flavor_info = json.load(json_file)
        flavor_info["descriptors"] = flavor_descriptors
        flavor_info["linters"] = flavor_linters
        os.makedirs(os.path.dirname(flavor_file), exist_ok=True)
        with open(flavor_file, "w", encoding="utf-8") as outfile:
            json.dump(flavor_info, outfile, indent=4, sort_keys=True)
            outfile.write("\n")
        # Write in global flavors files
        with open(GLOBAL_FLAVORS_FILE, "r", encoding="utf-8") as json_file:
            global_flavors = json.load(json_file)
            global_flavors[flavor] = flavor_info
        with open(GLOBAL_FLAVORS_FILE, "w", encoding="utf-8") as outfile:
            json.dump(global_flavors, outfile, indent=4, sort_keys=True)
            outfile.write("\n")
        # Flavored dockerfile
        dockerfile = f"{FLAVORS_DIR}/{flavor}/Dockerfile"
        if not os.path.isdir(os.path.dirname(dockerfile)):
            os.makedirs(os.path.dirname(dockerfile), exist_ok=True)
        copyfile(f"{REPO_HOME}/Dockerfile", dockerfile)
        flavor_label = flavor_info["label"]
        comment = f"# MEGALINTER FLAVOR [{flavor}]: {flavor_label}"
        with open(dockerfile, "r+", encoding="utf-8") as f:
            first_line = f.readline().rstrip()
            if first_line.startswith("# syntax="):
                comment = f"{first_line}\n{comment}"
            else:
                f.seek(0)
            content = f.read()
            f.seek(0)
            f.truncate()
            f.write(f"{comment}\n{content}")
        # Generate action.yml
        if RELEASE is True:
            image_release = RELEASE_TAG
        else:
            image_release = DEFAULT_RELEASE
        flavor_x = f"[{flavor} flavor]"
        action_yml = f""" # Automatically {'@'}generated by build.py
name: "MegaLinter"
author: "Nicolas Vuillamy"
description: "{flavor_x} Combine all available linters to automatically validate your sources without configuration !"
outputs:
  has_updated_sources:
    description: "0 if no source file has been updated, 1 if source files has been updated"
runs:
  using: "docker"
  image: "docker://{ML_DOCKER_IMAGE}-{flavor}:{image_release}"
  args:
    - "-v"
    - "/var/run/docker.sock:/var/run/docker.sock:rw"
branding:
  icon: "check"
  color: "green"
"""
        flavor_action_yml = f"{FLAVORS_DIR}/{flavor}/action.yml"
        with open(flavor_action_yml, "w", encoding="utf-8") as file:
            file.write(action_yml)
            logging.info(f"Updated {flavor_action_yml}")
    extra_lines = [
        "COPY entrypoint.sh /entrypoint.sh",
        "RUN chmod +x entrypoint.sh",
        'ENTRYPOINT ["/bin/bash", "/entrypoint.sh"]',
    ]
    build_dockerfile(
        dockerfile,
        descriptor_and_linters,
        requires_docker,
        flavor,
        extra_lines,
        DEFAULT_DOCKERFILE_FLAVOR_ARGS.copy(),
        {"cargo": DEFAULT_DOCKERFILE_FLAVOR_CARGO_PACKAGES.copy()},
    )


def build_dockerfile(
    dockerfile,
    descriptor_and_linters,
    requires_docker,
    flavor,
    extra_lines,
    extra_args=None,
    extra_packages=None,
):
    """Build a Dockerfile based on descriptors and linters"""
    if extra_packages is None:
        extra_packages = {}
    # Gather all dockerfile commands
    docker_from = []
    docker_arg = DEFAULT_DOCKERFILE_ARGS.copy()
    if extra_args is not None:
        docker_arg += extra_args
    docker_copy = []
    docker_other = []
    all_dockerfile_items = []
    apk_packages = DEFAULT_DOCKERFILE_APK_PACKAGES.copy()
    npm_packages = []
    pip_packages = []
    pipvenv_packages = {}
    gem_packages = []
    cargo_packages = [] if "cargo" not in extra_packages else extra_packages["cargo"]
    is_docker_other_run = False
    # Manage docker
    if requires_docker is True:
        docker_arg += DEFAULT_DOCKERFILE_DOCKER_ARGS.copy()
        apk_packages += DEFAULT_DOCKERFILE_DOCKER_APK_PACKAGES.copy()
        docker_other += [
            "RUN rc-update add docker boot && (rc-service docker start || true)"
        ]
        is_docker_other_run = True
    for item in descriptor_and_linters:
        if "install" not in item:
            item["install"] = {}
        # Collect Dockerfile items
        if "dockerfile" in item["install"]:
            item_label = item.get("linter_name", item.get("descriptor_id", ""))
            docker_other += [f"# {item_label} installation"]
            for dockerfile_item in item["install"]["dockerfile"]:
                # FROM
                if dockerfile_item.startswith("FROM"):
                    if dockerfile_item in all_dockerfile_items:
                        dockerfile_item = (
                            "# Next FROM line commented because already managed by another linter\n"
                            "# " + "\n# ".join(dockerfile_item.splitlines())
                        )
                    docker_from += [dockerfile_item]
                # ARG
                elif dockerfile_item.startswith("ARG") or (
                    len(dockerfile_item.splitlines()) > 1
                    and dockerfile_item.splitlines()[0].startswith("# renovate: ")
                    and dockerfile_item.splitlines()[1].startswith("ARG")
                ):
                    docker_arg += [dockerfile_item]
                # COPY
                elif dockerfile_item.startswith("COPY"):
                    if dockerfile_item in all_dockerfile_items:
                        dockerfile_item = (
                            "# Next COPY line commented because already managed by another linter\n"
                            "# " + "\n# ".join(dockerfile_item.splitlines())
                        )
                    docker_copy += [dockerfile_item]
                    docker_other += [
                        "# Managed with "
                        + "\n#              ".join(dockerfile_item.splitlines())
                    ]
                # Already used item
                elif (
                    dockerfile_item in all_dockerfile_items
                    or dockerfile_item.replace(
                        "RUN ", "RUN --mount=type=secret,id=GITHUB_TOKEN "
                    )
                    in all_dockerfile_items
                ):
                    dockerfile_item = (
                        "# Next line commented because already managed by another linter\n"
                        "# " + "\n# ".join(dockerfile_item.splitlines())
                    )
                    docker_other += [dockerfile_item]
                # RUN (standalone with GITHUB_TOKEN)
                elif (
                    dockerfile_item.startswith("RUN")
                    and "GITHUB_TOKEN" in dockerfile_item
                ):
                    dockerfile_item_cmd = dockerfile_item.replace(
                        "RUN ", "RUN --mount=type=secret,id=GITHUB_TOKEN "
                    )
                    docker_other += [dockerfile_item_cmd]
                    is_docker_other_run = False
                # RUN (start)
                elif dockerfile_item.startswith("RUN") and is_docker_other_run is False:
                    docker_other += [dockerfile_item]
                    is_docker_other_run = True
                # RUN (append)
                elif dockerfile_item.startswith("RUN") and is_docker_other_run is True:
                    dockerfile_item_cmd = dockerfile_item.replace("RUN", "    &&")
                    # Add \ in previous instruction line
                    for index, prev_instruction_line in reversed(
                        list(enumerate(docker_other))
                    ):
                        if (
                            prev_instruction_line.strip() != ""
                            and not prev_instruction_line.startswith("#")
                        ):
                            # Remove last char if \n
                            prev_instruction_line = (
                                prev_instruction_line
                                if not prev_instruction_line.endswith("\n")
                                else prev_instruction_line[:-1]
                            )
                            docker_other[index] = prev_instruction_line + " \\"
                            break
                    docker_other += [dockerfile_item_cmd]
                # Other
                else:
                    is_docker_other_run = False
                    docker_other += [dockerfile_item]
                all_dockerfile_items += [dockerfile_item]
            docker_other += ["#"]
        # Collect python packages
        if "apk" in item["install"]:
            apk_packages += item["install"]["apk"]
        # Collect npm packages
        if "npm" in item["install"]:
            npm_packages += item["install"]["npm"]
        # Collect python for venvs
        if "linter_name" in item and "pip" in item["install"]:
            pipvenv_packages[item["linter_name"]] = item["install"]["pip"]
        # Collect python packages
        if "pip" in item["install"]:
            pip_packages += item["install"]["pip"]
        # Collect ruby packages
        if "gem" in item["install"]:
            gem_packages += item["install"]["gem"]
        # Collect cargo packages (rust)
        if "cargo" in item["install"]:
            cargo_packages += item["install"]["cargo"]
    # Add node install if node packages are here
    if len(npm_packages) > 0:
        docker_arg += DEFAULT_DOCKERFILE_NPM_ARGS.copy()
        apk_packages += DEFAULT_DOCKERFILE_NPM_APK_PACKAGES.copy()
    # Add ruby apk packages if gem packages are here
    if len(gem_packages) > 0:
        docker_arg += DEFAULT_DOCKERFILE_GEM_ARGS.copy()
        apk_packages += DEFAULT_DOCKERFILE_GEM_APK_PACKAGES.copy()
    if len(pip_packages) > 0:
        docker_arg += DEFAULT_DOCKERFILE_PIP_ARGS.copy()
    if len(pipvenv_packages) > 0:
        docker_arg += DEFAULT_DOCKERFILE_PIPENV_ARGS.copy()
    if len(cargo_packages) > 0:
        docker_arg += DEFAULT_DOCKERFILE_RUST_ARGS.copy()
    # Separate args used in FROM instructions from others
    all_from_instructions = "\n".join(list(dict.fromkeys(docker_from)))
    docker_arg_top = []
    docker_arg_main = []
    docker_arg_main_extra = []
    for docker_arg_item in docker_arg:
        match = re.match(
            r"(?:# renovate: .*\n)?ARG\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*=?\s*",
            docker_arg_item,
        )
        arg_name = match.group(1)
        if arg_name in all_from_instructions:
            docker_arg_top += [docker_arg_item]
        else:
            docker_arg_main += [docker_arg_item]

        if docker_arg_item in docker_arg_top:
            docker_arg_main_extra += [f"ARG {arg_name}"]

    if len(docker_arg_main_extra) > 0:
        docker_arg_main_extra.insert(0, "")
        docker_arg_main += docker_arg_main_extra
    # Replace between tags in Dockerfile
    # Commands
    replace_in_file(
        dockerfile,
        "#FROM__START",
        "#FROM__END",
        "\n".join(list(dict.fromkeys(docker_from))),
    )
    replace_in_file(
        dockerfile,
        "#ARGTOP__START",
        "#ARGTOP__END",
        "\n".join(list(dict.fromkeys(docker_arg_top))),
    )
    replace_in_file(
        dockerfile,
        "#ARG__START",
        "#ARG__END",
        "\n".join(list(dict.fromkeys(docker_arg_main))),
    )
    replace_in_file(
        dockerfile,
        "#COPY__START",
        "#COPY__END",
        "\n".join(docker_copy),
    )
    replace_in_file(
        dockerfile,
        "#OTHER__START",
        "#OTHER__END",
        "\n".join(docker_other),
    )
    # apk packages
    apk_install_command = ""
    if len(apk_packages) > 0:
        apk_install_command = (
            "RUN apk -U --no-cache upgrade"
            + " \\\n    && apk add --no-cache \\\n                "
            + " \\\n                ".join(list(dict.fromkeys(apk_packages)))
            + " \\\n    && git config --global core.autocrlf true"
        )
    replace_in_file(dockerfile, "#APK__START", "#APK__END", apk_install_command)
    # cargo packages
    cargo_install_command = ""
    keep_rustup = False
    if len(cargo_packages) > 0:
        rust_commands = []
        if "clippy" in cargo_packages:
            cargo_packages.remove("clippy")
            rust_commands += ["rustup component add clippy"]
            keep_rustup = True
        # Only COMPILER_ONLY in descriptors just to have rust toolchain in the Dockerfile
        if all(p == "COMPILER_ONLY" for p in cargo_packages):
            rust_commands += [
                'echo "No cargo package to install, we just need rust for dependencies"'
            ]
            keep_rustup = True
        # Cargo packages to install minus empty package
        elif len(cargo_packages) > 0:
            cargo_packages = [
                p for p in cargo_packages if p != "COMPILER_ONLY"
            ]  # remove empty string packages
            cargo_cmd = "cargo install --force --locked " + " ".join(
                list(dict.fromkeys(cargo_packages))
            )
            rust_commands += [cargo_cmd]
        rustup_cargo_cmd = " && ".join(rust_commands)
        cargo_install_command = (
            "RUN curl https://sh.rustup.rs -sSf |"
            + " sh -s -- -y --profile minimal --default-toolchain ${RUST_RUST_VERSION} \\\n"
            + '    && export PATH="/root/.cargo/bin:/root/.cargo/env:${PATH}" \\\n'
            + "    && rustup default stable \\\n"
            + f"    && {rustup_cargo_cmd} \\\n"
            + "    && rm -rf /root/.cargo/registry /root/.cargo/git "
            + "/root/.cache/sccache"
            + (" /root/.rustup" if keep_rustup is False else "")
            + "\n"
            + 'ENV PATH="/root/.cargo/bin:/root/.cargo/env:${PATH}"'
        )
    replace_in_file(dockerfile, "#CARGO__START", "#CARGO__END", cargo_install_command)
    # NPM packages
    npm_install_command = ""
    if len(npm_packages) > 0:
        npm_install_command = (
            "WORKDIR /node-deps\n"
            + "RUN npm --no-cache install --ignore-scripts --omit=dev \\\n                "
            + " \\\n                ".join(list(dict.fromkeys(npm_packages)))
            + " && \\\n"
            #    + '       echo "Fixing audit issues with npm…" \\\n'
            #    + "    && npm audit fix --audit-level=critical || true \\\n" # Deactivated for now
            + '    echo "Cleaning npm cache…" \\\n'
            + "    && (npm cache clean --force || true) \\\n"
            + '    && echo "Changing owner of node_modules files…" \\\n'
            + '    && chown -R "$(id -u)":"$(id -g)" node_modules # fix for https://github.com/npm/cli/issues/5900 \\\n'
            + '    && echo "Removing extra node_module files…" \\\n'
            + '    && find . \\( -not -path "/proc" \\)'
            + " -and \\( -type f"
            + ' \\( -iname "*.d.ts"'
            + ' -o -iname "*.map"'
            + ' -o -iname "*.npmignore"'
            + ' -o -iname "*.travis.yml"'
            + ' -o -iname "CHANGELOG.md"'
            + ' -o -iname "README.md"'
            + ' -o -iname ".package-lock.json"'
            + ' -o -iname "package-lock.json"'
            + " \\) -o -type d -name /root/.npm/_cacache \\) -delete\n"
            + "WORKDIR /\n"
        )
    replace_in_file(dockerfile, "#NPM__START", "#NPM__END", npm_install_command)
    # Python pip packages
    pip_install_command = ""
    if len(pip_packages) > 0:
        pip_install_command = (
            "RUN PYTHONDONTWRITEBYTECODE=1 pip3 install --no-cache-dir pip==${PIP_PIP_VERSION} &&"
            + " PYTHONDONTWRITEBYTECODE=1 pip3 install --no-cache-dir \\\n          '"
            + "' \\\n          '".join(list(dict.fromkeys(pip_packages)))
            + "' && \\\n"
            + r"find . \( -type f \( -iname \*.pyc -o -iname \*.pyo \) -o -type d -iname __pycache__ \) -delete"
            + " \\\n    && "
            + "rm -rf /root/.cache"
        )
    replace_in_file(dockerfile, "#PIP__START", "#PIP__END", pip_install_command)
    # Python packages in venv
    if len(pipvenv_packages.items()) > 0:
        pipenv_install_command = (
            "RUN PYTHONDONTWRITEBYTECODE=1 pip3 install"
            " --no-cache-dir pip==${PIP_PIP_VERSION} virtualenv==${PIP_VIRTUALENV_VERSION} \\\n"
        )
        env_path_command = 'ENV PATH="${PATH}"'
        for pip_linter, pip_linter_packages in pipvenv_packages.items():
            pipenv_install_command += (
                f'    && mkdir -p "/venvs/{pip_linter}" '
                + f'&& cd "/venvs/{pip_linter}" '
                + "&& virtualenv . "
                + "&& source bin/activate "
                + "&& PYTHONDONTWRITEBYTECODE=1 pip3 install --no-cache-dir "
                + (" ".join(pip_linter_packages))
                + " "
                + "&& deactivate "
                + "&& cd ./../.. \\\n"
            )
            env_path_command += f":/venvs/{pip_linter}/bin"
        pipenv_install_command = pipenv_install_command[:-2]  # remove last \
        pipenv_install_command += (
            " \\\n    && "
            + r"find /venvs \( -type f \( -iname \*.pyc -o -iname \*.pyo \) -o -type d -iname __pycache__ \) -delete"
            + " \\\n    && "
            + "rm -rf /root/.cache\n"
            + env_path_command
        )
    else:
        pipenv_install_command = ""
    replace_in_file(
        dockerfile, "#PIPVENV__START", "#PIPVENV__END", pipenv_install_command
    )

    # Ruby gem packages
    gem_install_command = ""
    if len(gem_packages) > 0:
        gem_install_command = (
            "RUN echo 'gem: --no-document' >> ~/.gemrc && \\\n"
            + "    gem install \\\n          "
            + " \\\n          ".join(list(dict.fromkeys(gem_packages)))
        )
    replace_in_file(dockerfile, "#GEM__START", "#GEM__END", gem_install_command)
    flavor_env = f"ENV MEGALINTER_FLAVOR={flavor}"
    replace_in_file(dockerfile, "#FLAVOR__START", "#FLAVOR__END", flavor_env)
    replace_in_file(
        dockerfile,
        "#EXTRA_DOCKERFILE_LINES__START",
        "#EXTRA_DOCKERFILE_LINES__END",
        "\n".join(extra_lines),
    )


def match_flavor(item, flavor, flavor_info):
    """Check if an item matches a flavor"""
    is_strict = "strict" in flavor_info and flavor_info["strict"] is True
    if "disabled" in item and item["disabled"] is True:
        return
    if (
        "descriptor_flavors_exclude" in item
        and flavor in item["descriptor_flavors_exclude"]
    ):
        return False
    # Flavor all
    elif flavor == "all":
        return True
    # Formatter flavor
    elif flavor == "formatters":
        if "is_formatter" in item and item["is_formatter"] is True:
            return True
        elif (
            "descriptor_flavors" in item
            and flavor in item["descriptor_flavors"]
            and "linter_name" not in item
        ):
            return True
        else:
            return False
    # Other flavors
    elif "descriptor_flavors" in item:
        if flavor in item["descriptor_flavors"] or (
            "all_flavors" in item["descriptor_flavors"]
            and not flavor.endswith("_light")
            and "cupcake" not in flavor
            and not is_strict
        ):
            return True
    return False


def generate_linter_dockerfiles():
    """Automatically generate Dockerfile for standalone linters"""
    # Remove all the contents of LINTERS_DIR beforehand so that the result is deterministic
    if DELETE_DOCKERFILES is True:
        shutil.rmtree(os.path.realpath(LINTERS_DIR))
    # Browse descriptors
    linters_md = "# Standalone linter docker images\n\n"
    linters_md += "| Linter key | Docker image | Size |\n"
    linters_md += "| :----------| :----------- | :--: |\n"
    descriptor_files = megalinter.linter_factory.list_descriptor_files()
    gha_workflow_yml = ["        linter:", "          ["]
    for descriptor_file in descriptor_files:
        descriptor_items = []
        with open(descriptor_file, "r", encoding="utf-8") as f:
            descriptor = yaml.safe_load(f)
        if "install" in descriptor:
            descriptor_items += [descriptor]
        descriptor_linters = megalinter.linter_factory.build_descriptor_linters(
            descriptor_file, {"request_id": "build"}
        )
        # Browse descriptor linters
        for linter in descriptor_linters:
            # Unique linter dockerfile
            linter_lower_name = linter.name.lower()
            dockerfile = f"{LINTERS_DIR}/{linter_lower_name}/Dockerfile"
            if not os.path.isdir(os.path.dirname(dockerfile)):
                os.makedirs(os.path.dirname(dockerfile), exist_ok=True)
            requires_docker = False
            if linter.cli_docker_image is not None:
                requires_docker = True
            descriptor_and_linter = descriptor_items + [vars(linter)]
            copyfile(f"{REPO_HOME}/Dockerfile", dockerfile)
            extra_lines = [
                f"ENV ENABLE_LINTERS={linter.name} \\",
                "    FLAVOR_SUGGESTIONS=false \\",
                f"    SINGLE_LINTER={linter.name} \\",
                "    PRINT_ALPACA=false \\",
                "    LOG_FILE=none \\",
                "    SARIF_REPORTER=true \\",
                "    TEXT_REPORTER=false \\",
                "    UPDATED_SOURCES_REPORTER=false \\",
                "    GITHUB_STATUS_REPORTER=false \\",
                "    GITHUB_COMMENT_REPORTER=false \\",
                "    EMAIL_REPORTER=false \\",
                "    API_REPORTER=false \\",
                "    FILEIO_REPORTER=false \\",
                "    CONFIG_REPORTER=false \\",
                "    SARIF_TO_HUMAN=false" "",
                # "EXPOSE 80",
                "RUN mkdir /root/docker_ssh && mkdir /usr/bin/megalinter-sh",
                "EXPOSE 22",
                "COPY entrypoint.sh /entrypoint.sh",
                "COPY sh /usr/bin/megalinter-sh",
                "COPY sh/megalinter_exec /usr/bin/megalinter_exec",
                "COPY sh/motd /etc/motd",
                'RUN find /usr/bin/megalinter-sh/ -type f -iname "*.sh" -exec chmod +x {} \\; && \\',
                "    chmod +x entrypoint.sh && \\",
                "    chmod +x /usr/bin/megalinter_exec && \\",
                "    echo \"alias megalinter='python -m megalinter.run'\" >> ~/.bashrc && source ~/.bashrc && \\",
                "    echo \"alias megalinter_exec='/usr/bin/megalinter_exec'\" >> ~/.bashrc && source ~/.bashrc",
                'RUN export STANDALONE_LINTER_VERSION="$(python -m megalinter.run --input /tmp --linterversion)" && \\',
                "    echo $STANDALONE_LINTER_VERSION",
                # "    echo $STANDALONE_LINTER_VERSION >> ~/.bashrc && source ~/.bashrc",
                'ENTRYPOINT ["/bin/bash", "/entrypoint.sh"]',
            ]
            build_dockerfile(
                dockerfile, descriptor_and_linter, requires_docker, "none", extra_lines
            )
            gha_workflow_yml += [f'            "{linter_lower_name}",']
            docker_image = f"{ML_DOCKER_IMAGE}-only-{linter_lower_name}:{VERSION_V}"
            docker_image_badge = (
                f"![Docker Image Size (tag)]({BASE_SHIELD_IMAGE_LINK}/"
                f"{ML_DOCKER_IMAGE}-only-{linter_lower_name}/{VERSION_V})"
            )
            linters_md += (
                f"| {linter.name} | {docker_image} | {docker_image_badge}  |\n"
            )

    # Update github action workflow
    gha_workflow_yml += ["          ]"]
    replace_in_file(
        f"{REPO_HOME}/.github/workflows/deploy-DEV-linters.yml",
        "# linters-start",
        "# linters-end",
        "\n".join(gha_workflow_yml),
    )
    replace_in_file(
        f"{REPO_HOME}/.github/workflows/deploy-BETA-linters.yml",
        "# linters-start",
        "# linters-end",
        "\n".join(gha_workflow_yml),
    )
    replace_in_file(
        f"{REPO_HOME}/.github/workflows/deploy-RELEASE-linters.yml",
        "# linters-start",
        "# linters-end",
        "\n".join(gha_workflow_yml),
    )
    # Write MD file
    file = open(f"{REPO_HOME}/docs/standalone-linters.md", "w", encoding="utf-8")
    file.write(linters_md + "\n")
    file.close()


# Import functions that need to be available but will be defined in other modules
def update_mkdocs_and_workflow_yml_with_flavors():
    """Placeholder - will be imported from stats_collector module"""
    pass


def update_docker_pulls_counter():
    """Placeholder - will be imported from stats_collector module"""
    pass
